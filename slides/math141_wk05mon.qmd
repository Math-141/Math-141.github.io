---
pagetitle: "Multiple Linear Regression"
editor: source
format: 
  revealjs:
    chalkboard: true
    incremental: true
    theme: [default, custom.scss]
    height: 900
    width: 1600
    slide-number: c
    auto-stretch: false
    callout-appearance: simple
    pdf-max-pages-per-slide: 2
    menu: 
      side: right
      numbers: true
execute:
  echo: true
  warning: false
  message: false
---

```{r}
#| include: false
#| warning: false
#| message: false

knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      fig.retina = 3, fig.align = 'center')
library(knitr)
library(tidyverse)
```

::::: columns
::: {.column .center width="60%"}
![](img/DAW.jpeg){width="90%"}
:::

::: {.column .center width="40%"}
<br>

[Multiple Linear Regression]{.custom-title}

<br> <br> 

[Grayson White]{.custom-subtitle}

[Math 141 <br> Week 5 \| Fall 2025]{.custom-subtitle}
:::
:::::

------------------------------------------------------------------------

## Announcements

-   Discuss Week 4 Feedback!

### Goals for Today

-   Handling categorical, explanatory variables and quantitative variables at the same time.
-   Equal slopes model
-   Different slopes model


------------------------------------------------------------------------

### Multiple Linear Regression

Form of the Model:

$$ 
\begin{align}
y &= \beta_o + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p + \epsilon
\end{align}
$$

How does extending to more predictors change our process?

-   What **doesn't** change:
    -   Still use **Method of Least Squares** to estimate coefficients
    -   Still use `lm()` to fit the model and `predict()` for prediction
-   What **does** change:
    -   Meaning of the coefficients are more complicated and depend on other variables in the model
    -   Need to decide which variables to include and how (linear term, squared term...)

------------------------------------------------------------------------

### Multiple Linear Regression

-   We are going to see a few examples of multiple linear regression this week.

-   We will need to return to modeling later in the course once we have learned about statistical inference (i.e., confidence intervals and p-values).

------------------------------------------------------------------------

## Example

:::: {.columns}

::: {.column width=50%}

Meadowfoam is a plant that grows in the Pacific Northwest and is harvested for its seed oil. In a randomized experiment, researchers at Oregon State University looked at how two light-related factors influenced the number of flowers per meadowfoam plant, the primary measure of productivity for this plant. The two light measures were light intensity (in mmol/ $m^2$ /sec) and the timing of onset of the light (early or late in terms of photo periodic floral induction).

:::

::: {.column width=50%}

![](img/meadowfoam.jpg){fig-align='center'}

:::

::::


:::{.fragment}

**Response variable?**

:::

:::{.fragment}


**Explanatory variables?**

:::

:::{.fragment}

**Model Form?**

:::

------------------------------------------------------------------------

### Data Loading and Wrangling

```{r}
library(tidyverse)
library(Sleuth3)
data(case0901)

# Recode the timing variable
count(case0901, Time)
case0901 <- case0901 %>%
  mutate(TimeCat = case_when(
    Time == 1 ~ "Late",
    Time == 2 ~ "Early"
    )) 
count(case0901, TimeCat)
```

------------------------------------------------------------------------

### Visualizing the Data

```{r}
#| output-location: column

ggplot(case0901,
       aes(x = Intensity,
           y = Flowers,
           color = TimeCat)) + 
  geom_point(size = 4)

```

Why don't I have to include `data =` and `mapping =` in my `ggplot()` layer?

------------------------------------------------------------------------

### Building the Linear Regression Model

Full model form:

```{r}
modFlowers <- lm(Flowers ~ Intensity + TimeCat, data = case0901)

library(moderndive)
get_regression_table(modFlowers)
```

::: nonincremental
-   Estimated regression line for $x_2 = 1$:

<br> <br>

-   Estimated regression line for $x_2 = 0$:
:::

------------------------------------------------------------------------

### Appropriateness of Model Form

```{r}
#| output-location: column

ggplot(case0901, 
       aes(x = Intensity,
           y = Flowers,
           color = TimeCat)) + 
  geom_point(size = 4) + 
  geom_smooth(method = "lm", se = FALSE)

```

Is the assumption of **equal slopes** reasonable here?

------------------------------------------------------------------------

### Prediction

```{r}
flowersNew <- data.frame(Intensity = c(700, 700), TimeCat = c("Early", "Late"))
flowersNew

predict(modFlowers, newdata = flowersNew)
```

------------------------------------------------------------------------

### Returning to the Palmer Penguins

```{r}
library(palmerpenguins)
```

![](img/penguins.png){fig-align="center"}

------------------------------------------------------------------------

### Last time:

We predicted a penguin's bill length based on their species.

::: {.fragment}


```{r}
#| output-location: column

ggplot(penguins, aes(x = species, y = bill_length_mm, fill = species)) +
  geom_boxplot() + 
  scale_fill_manual(values = c("steelblue",
                               "goldenrod", 
                               "plum3")) +
  stat_summary(fun = mean, 
               geom = "point", 
               size = 3,
               color = "deeppink") + 
  guides(fill = "none") +
  theme_bw()
```


:::

-   Pink dots represent the mean value in each group. 
-   For the single categorical variable model, those pink dots are the predicted values for each group. 

------------------------------------------------------------------------

### This time: 

We'll incorporate bill depth for prediction!

::: {.fragment}


```{r}
#| output-location: column

ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm)) +
  geom_point(size = 2) + 
  geom_smooth(method = "lm", se = FALSE, color = "red") + 
  theme_bw()
```


:::

-   A moderate negative relationship between bill length and bill depth! 
-   Does this make sense?

------------------------------------------------------------------------

![](img/culmen_depth.png){fig-align='center'}


------------------------------------------------------------------------

### What if we include both explanatory variables? 

::: {.fragment}


```{r}
#| output-location: column

ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm, color = species)) +
  geom_point(size = 2) + 
  geom_smooth(inherit.aes = FALSE, 
              mapping = aes(x = bill_depth_mm,
                            y = bill_length_mm),
              method = "lm",
              se = FALSE,
              color = "red") + 
  geom_parallel_slopes(se = FALSE) + 
  scale_color_manual(values = c("steelblue",
                               "goldenrod", 
                               "plum3")) +
  theme_bw() +
  theme(legend.position = "bottom")
```

:::

-   **Negative** relationships between bill depth and bill length overall.
-   **Positive** relationships between bill depth and bill length when accounting for species! 
-   **What is going on here??**
-   This is a case of **Simpson's Paradox**. 

------------------------------------------------------------------------

### Three candidate models

:::: {.columns}

::: {.column width=50%}

```{r}
species_mod <- lm(bill_length_mm ~ species, penguins)
get_regression_table(species_mod) %>%
  select(term, estimate)
```

<br>

::: {.fragment}

```{r}
depth_mod <- lm(bill_length_mm ~ bill_depth_mm, penguins)
get_regression_table(depth_mod) %>%
  select(term, estimate)
```

:::

:::

::: {.column width=50%}

<br>

::: {.fragment}

```{r}
both_mod <- lm(bill_length_mm ~ bill_depth_mm + species, penguins)
get_regression_table(both_mod) %>%
  select(term, estimate)
```

:::

:::

::::

-   **Coefficient interpretations**?

------------------------------------------------------------------------

### Interpreting the Multiple Regression Equation

```{r}
get_regression_table(both_mod)
```
:::{.fragment}

$$
\hat{y}= 13.2 + 1.39 \cdot x_{\textrm{Bill Depth}} + 9.94 \cdot  x_{\textrm{Species:Chinstrap}} + 13.4 \cdot x_{\textrm{Species:Gentoo}}
$$

:::

-   **Slope Coefficient on Quantitative Variable:** The *expected/predicted* change in response variable, *on average*, per unit increase in the explanatory variable, *holding all other variables constant*.
    -   Example: We expect a 1.394mm increase in bill length for every 1mm increase in bill depth, on average, after holding species constant.


------------------------------------------------------------------------

### Interpreting the Multiple Regression Equation

```{r}
get_regression_table(both_mod)
```


$$
\hat{y}= 13.2 + 1.39 \cdot x_{\textrm{Bill Depth}} + 9.94 \cdot  x_{\textrm{Species:Chinstrap}} + 13.4 \cdot x_{\textrm{Species:Gentoo}}
$$


    
-   **Intercept Coefficient:** The *expected/predicted* value of the response, *on average*, when all explanatory variables are *set to 0*.
    -   What does setting species to 0 mean in this context?


------------------------------------------------------------------------

## Returning to our MLR model


```{r}
#| output-location: column

ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm, color = species)) +
  geom_point(size = 2) + 
  geom_parallel_slopes(se = FALSE) + 
  scale_color_manual(values = c("steelblue",
                               "goldenrod", 
                               "plum3")) +
  theme_bw() 
```

**Are equal slopes a reasonable assumption here?**

## Different Slopes Model


```{r}
#| output-location: column

ggplot(penguins, aes(x = bill_depth_mm, y = bill_length_mm, color = species)) +
  geom_point(size = 2) + 
  geom_smooth(method = "lm", se = FALSE) + 
  scale_color_manual(values = c("steelblue",
                               "goldenrod", 
                               "plum3")) +
  theme_bw() 
```

-   **Equal slopes** models force the relationship between quantitative predictors and the response variable to be the same for each group in the model.

-   In contrast, **different slopes** models allow for **different relationships** between quantitative predictors and the response variable for each group in the model. 

-   How can we allow our model to have different slopes? 

## Contrasting model forms

Recall the equal slopes model:

$$
y = \beta_o + \beta_1 \cdot x_{\textrm{Bill Depth}} + \beta_2 \cdot  x_{\textrm{Species:Chinstrap}} + \beta_3 \cdot x_{\textrm{Species:Gentoo}} + \epsilon
$$

<br>

:::{.fragment}

How can we allow the slopes to vary? 

:::

::: {.fragment}

$$
y = \beta_o + \beta_1 \cdot x_{\textrm{Bill Depth}} + \beta_2 \cdot  x_{\textrm{Species:Chinstrap}} + \beta_3 \cdot x_{\textrm{Species:Gentoo}} + \\
\beta_4 \cdot x_{\textrm{Bill Depth}} \cdot x_{\textrm{Species:Chinstrap}} + \beta_5 \cdot x_{\textrm{Bill Depth}} \cdot x_{\textrm{Species:Gentoo}} + \epsilon 
$$

:::

-   **Coefficient interpretation?**

## Different Slopes Model in R

```{r}
same_slope <- lm(bill_length_mm ~ bill_depth_mm + species, penguins)

diff_slope <- lm(bill_length_mm ~ bill_depth_mm * species, penguins)
```

:::{.fragment}

```{r}
get_regression_table(same_slope)
```

:::

<br>

:::{.fragment}

```{r}
get_regression_table(diff_slope)
```

:::


## Next time

-   Linear regression with multiple quantitative variables
-   Linear regression with curved relationships
-   Discuss an article from *The Quest* 


