---
pagetitle: "Data Collection"
editor: source
format: 
  revealjs:
    chalkboard: true
    incremental: true
    theme: [default, custom.scss]
    height: 900
    width: 1600
    slide-number: c
    auto-stretch: false
    callout-appearance: simple
    pdf-max-pages-per-slide: 2
    menu: 
      side: right
      numbers: true
execute:
  echo: true
  warning: false
  message: false
---

```{r}
#| include: false
#| warning: false
#| message: false

knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      fig.retina = 3, fig.align = 'center')
library(knitr)
library(tidyverse)
```

::::: columns
::: {.column .center width="60%"}
![](img/DAW.jpeg){width="90%"}
:::

::: {.column .center width="40%"}
<br>

[Data Collection]{.custom-title}

<br> <br> <br> <br> <br> 

[Grayson White]{.custom-subtitle}

[Math 141 <br> Week 3 \| Fall 2025]{.custom-subtitle}
:::
:::::

------------------------------------------------------------------------

## Goals for Today

-   Cover data collection/acquisition.

------------------------------------------------------------------------

### When to Get Coding Help

`r emo::ji("cry")` *"I have no idea how to do this problem."*

::: fragment
→ Ask someone to point you to an similar example from the lecture, handouts, and guides.
:::

::: fragment
→ Talk it through with a course assistant, a fellow Math 141 student, or Grayson so together we can verbalize the process of going from Q to A.
:::

<br>

::: fragment
`r emo::ji("rage")` *"I am getting a weird error but really think my code is correct/on the right track/matches the examples from class."*
:::

::: fragment
→ It is time for a second pair of eyes. Don't stare at the error for over 10 minutes.
:::

<br>

::: fragment
`r emo::ji("star-struck")` And lots of other times too! `r emo::ji("grimace")`
:::

------------------------------------------------------------------------

### When to Get Help

Remember:

::: fragment
→ Struggling is part of learning.
:::

::: fragment
→ But let us help you ensure it is a **productive** struggle.
:::

::: fragment
→ Struggling does NOT mean you are bad at stats, it actually means you are doing the work to **learn** the material!
:::

------------------------------------------------------------------------

## Now for Data Collection

![](img/DAW.png){width="50%" fig-align="center"}

------------------------------------------------------------------------

## Motivating Our Discussion of Data Collection

![](img/twitter-study-design.png){width="50%" fig-align="center"}

## Who are the data supposed to represent?

![](img/week4.002.jpeg){width="75%" fig-align="center"}

**Key questions:**

-   What evidence is there that the data are **representative**?
-   Who is present? Who is absent?
-   Who is overrepresented? Who is underrepresented?

------------------------------------------------------------------------

## Who are the data supposed to represent?

![](img/week4.003.jpeg){width="80%" fig-align="center"}

**Census**: We have data on the whole population!

------------------------------------------------------------------------

## Who are the data supposed to represent?

![](img/sampling.002.jpeg){width="85%" fig-align="center"}

------------------------------------------------------------------------

## Who are the data supposed to represent?

![](img/week4.005.jpeg){width="75%" fig-align="center"}

**Key questions:**

-   What evidence is there that the **sample** is **representative** of the **population**?
-   Who is present? Who is absent?
-   Who is overrepresented? Who is underrepresented?

------------------------------------------------------------------------

## Sampling Bias

![](img/sampling.001.jpeg){width="75%" fig-align="center"}

**Sampling bias**: When the sampled units are **systematically different** from the non-sampled units on the variables of interest.

------------------------------------------------------------------------

### Sampling Bias Example

The **Literary Digest** was a political magazine that correctly predicted the presidential outcomes from 1916 to 1932. In 1936, they conducted the most extensive (to that date) public opinion poll. They mailed questionnaires to over 10 million people (about 1/3 of US households) whose names and addresses they obtained from telephone books and vehicle registration lists.

**Population of Interest**:

<br>

**Sample**:

<br>

**Sampling bias**:

------------------------------------------------------------------------

## Random Sampling

Use random sampling (a random mechanism for selecting cases from the population) to remove sampling bias.

#### Types of random sampling

::: nonincremental
-   Simple random sampling

-   Cluster sampling

-   Stratified random sampling

-   Systematic sampling
:::

::: fragment
Why aren't all samples generated using simple random sampling?
:::

------------------------------------------------------------------------

### US Forest Inventory and Analysis Program

::::: columns
::: {.column width="15%"}
![](img/fs.png){fig-align="center"}
:::

::: {.column width="85%"}
> Mission: "Make and keep current a comprehensive inventory and analysis of the present and prospective conditions of and requirements for the renewable resources of the forest and rangelands of the US."
:::
:::::

::: fragment
Need a **random sample** of ground plots to say something about the state of our nation's forests!
:::

------------------------------------------------------------------------

### FIA: Simple Random Sampling

:::::: columns
:::: {.column width="50%"}
-   Break the landscape up into equally sized plots (\~1 acre).
-   Number each plot from 1 to 62,963,840.
-   Use a **random** mechanism to sample 10,494 plots.

::: fragment
```{r}
sample(x = 1:62963840, size = 10494) %>%
  head()
```
:::
::::

::: {.column width="50%"}
```{r, echo = FALSE}
library(maps)
library(tidyverse)
or_counties <- map_data("county", "oregon")
ggplot(or_counties, aes(long, lat, group = group)) +
  geom_polygon(fill = "olivedrab", colour = "olivedrab") + 
  coord_quickmap() +
  theme_void() + 
  geom_vline(xintercept=seq(-124.6, -116.4, by = 0.25), size = .2,
             color = "gray") +
  geom_hline(yintercept=seq(42, 46.3, by = 0.18), size = .2,
             color = "gray")
```
:::
::::::

::: fragment
Thoughts on this sampling design?
:::

------------------------------------------------------------------------

### FIA: Cluster Random Sampling

:::::: columns
:::: {.column width="50%"}
-   Break the landscape up into equally sized plots (\~1 acre).
-   Put each plot in a cluster.
    -   For our example: cluster = county.
-   Number each cluster.
-   Use a **random** mechanism to sample 2 clusters.
-   Sample **all** plots in those 2 clusters.

::: fragment
```{r}
sample(x = 1:36, size = 2) 
```
:::
::::

::: {.column width="50%"}
```{r, echo = FALSE}
library(maps)
library(tidyverse)
library(paletteer) 
pal <- paletteer_d("ggsci::default_igv")



or_counties <- map_data("county", "oregon")
ggplot(or_counties, aes(long, lat, group = group,
                          fill = factor(group))) +
  geom_polygon(colour = "olivedrab") + 
  coord_quickmap() +
  theme_void() + 
  geom_vline(xintercept=seq(-124.6, -116.4, by = 0.25), size = .2,
             color = "gray") +
  geom_hline(yintercept=seq(42, 46.3, by = 0.18), size = .2,
             color = "gray") + 
  scale_fill_manual(values = pal, name = "") +
  theme(legend.position = "none", 
        legend.text = element_text(size = 30))
```

![](img/legend.png){width='50%' fig-align='center'}

:::
::::::

::: fragment
Thoughts on this sampling design?
:::

------------------------------------------------------------------------

### FIA: Cluster Random Sampling

:::::: columns
:::: {.column width="50%"}
::: nonincremental
-   Break the landscape up into equally sized plots (\~1 acre).
-   Put each plot in a cluster.
    -   For our example: cluster = county.
-   Number each cluster.
-   Use a **random** mechanism to sample 2 clusters.
-   Take a **simple random sample** within the sampled clusters.
:::

```{r}
sample(x = 1:36, size = 2) 
```

```{r, eval = FALSE}
sample(x = 1:---, size = ---)
```
::::

::: {.column width="50%"}
```{r, echo = FALSE}
library(maps)
library(tidyverse)
library(paletteer) 
pal <- paletteer_d("ggsci::default_igv")



or_counties <- map_data("county", "oregon")
ggplot(or_counties, aes(long, lat, group = group,
                          fill = factor(group))) +
  geom_polygon(colour = "olivedrab") + 
  coord_quickmap() +
  theme_void() + 
  geom_vline(xintercept=seq(-124.6, -116.4, by = 0.25), size = .2,
             color = "gray") +
  geom_hline(yintercept=seq(42, 46.3, by = 0.18), size = .2,
             color = "gray") + 
  scale_fill_manual(values = pal, name = "") +
  theme(legend.position = "none", 
        legend.text = element_text(size = 30))
```

![](img/legend.png){width='50%' fig-align='center'}

:::
::::::

::: fragment
Subsampling within each sampled cluster is much more common than subsampling the whole sampled cluster!
:::

------------------------------------------------------------------------

### FIA: Cluster Random Sampling

::::: columns
::: {.column width="50%"}
```{r  out.width = "80%", echo = FALSE, fig.align = 'center'}
knitr::include_graphics("img/Forest-types-Map-combo.jpg")
```
:::

::: {.column width="50%"}
```{r, echo = FALSE}
pal <- paletteer_d("ggsci::default_igv")

ggplot(or_counties, aes(long, lat, group = group,
                          fill = factor(group))) +
  geom_polygon(colour = "olivedrab") + 
  coord_quickmap() +
  theme_void() + 
  scale_fill_manual(values = pal, name = "") +
  theme(legend.position = "none", 
        legend.text = element_text(size = 30))
```
:::
:::::

-   Are our clusters based on counties **homogeneous**?

-   Why is **homogeneity** important for cluster sampling?

------------------------------------------------------------------------

### FIA: Stratified Random Sampling

:::::: columns
:::: {.column width="50%"}
-   Break the landscape up into equally sized plots (\~1 acre).
-   Put each plot in a stratum.
    -   For our example: stratum = county.
-   Take a **simple random sample** within every stratum.
    -   Don't have to be equally sized!

::: fragment
```{r, eval = FALSE}
# Do this for each stratum
sample(x = 1:---, size = ---)
```
:::
::::

::: {.column width="50%"}
```{r, echo = FALSE}
library(maps)
library(tidyverse)
library(paletteer) 
pal <- paletteer_d("ggsci::default_igv")



or_counties <- map_data("county", "oregon")
ggplot(or_counties, aes(long, lat, group = group,
                          fill = factor(group))) +
  geom_polygon(colour = "olivedrab") + 
  coord_quickmap() +
  theme_void() + 
  geom_vline(xintercept=seq(-124.6, -116.4, by = 0.25), size = .2,
             color = "gray") +
  geom_hline(yintercept=seq(42, 46.3, by = 0.18), size = .2,
             color = "gray") + 
  scale_fill_manual(values = pal, name = "") +
  theme(legend.position = "none", 
        legend.text = element_text(size = 30))
```
:::
::::::

::: fragment
Thoughts on this sampling design?
:::

------------------------------------------------------------------------

### FIA: Systematic Random Sampling

:::::: columns
:::: {.column width="50%"}
This is FIA's **actual** sampling design (okay, slightly simplified).

-   Break the landscape up into equally sized plots (\~1 acre).
-   Number each plot from 1 to 62,963,840.
-   Use a **random** mechanism to pick starting point. Then sample about once every 6000 acres.

::: fragment
```{r}
sample(x = 1:62963840, size = 1) 
```
:::
::::

::: {.column width="50%"}
```{r, echo = FALSE}
library(maps)
library(tidyverse)
or_counties <- map_data("county", "oregon")
ggplot(or_counties, aes(long, lat, group = group)) +
  geom_polygon(fill = "olivedrab", colour = "olivedrab") + 
  coord_quickmap() +
  theme_void() + 
  geom_vline(xintercept=seq(-124.6, -116.4, by = 0.25), size = .2,
             color = "gray") +
  geom_hline(yintercept=seq(42, 46.3, by = 0.18), size = .2,
             color = "gray")
```
:::
::::::

::: fragment
Why is this design **better** than simple random sampling?
:::

------------------------------------------------------------------------

### National Health and Nutrition Examination Survey {.smaller}

::::: columns
::: {.column width="20%"}
![](img/nhanes_logo.jpg){fig-align="center"}
:::

::: {.column width="80%"}
> Mission: "Assess the health and nutritional status of adults and children in the United States."
:::
:::::

How are these data collected?

------------------------------------------------------------------------

### NHANES Sampling Design

-   **Stage 1**: US is stratified by geography and distribution of minority populations. Counties are randomly selected within each stratum.

-   **Stage 2**: From the sampled counties, city blocks are randomly selected. (City blocks are clusters.)

-   **Stage 3**: From sampled city blocks, households are randomly selected. (Households are clusters.)

-   **Stage 4**: From sampled households, people are randomly selected. For the sampled households, a mobile health vehicle goes to the house and medical professionals take the necessary measurements.

::: fragment
**Why don't they use simple random sampling?**
:::

------------------------------------------------------------------------

### Careful Using Non-Simple Random Sample Data

::::: columns
::: {.column width="50%"}
```{r, echo = FALSE}
library(NHANES)
library(tidyverse)

ggplot(data = NHANESraw, mapping = aes(x = fct_infreq(Race1),
                                    fill = Race1)) +
  geom_bar() + labs(x = "Race of Respondents", 
                    y = "Count",
                    title = "Original NHANES Data") +
  guides(fill = 'none')
```
:::

::: {.column .fragment width="50%"}
```{r, echo = FALSE}


ggplot(data = NHANES, mapping = aes(x = fct_infreq(Race1),
                                    fill = Race1)) +
  geom_bar() + labs(x = "Race of Respondents", 
                    y = "Count",
                    title = "NHANES Data Adjusted to Mimic SRS") +
  guides(fill = 'none')
```
:::
:::::


# Detour: Data Ethics

------------------------------------------------------------------------

### Data Ethics

> "Good statistical practice is fundamentally based on transparent assumptions, reproducible results, and valid interpretations." -- Committee on Professional Ethics of the American Statistical Association (ASA)

The ASA has created ["Ethical Guidelines for Statistical Practice"](https://www.amstat.org/ASA/Your-Career/Ethical-Guidelines-for-Statistical-Practice.aspx)

::: fragment
→ These guidelines are for EVERYONE doing statistical work.
:::

::: fragment
→ There are ethical decisions at all steps of the Data Analysis Process.
:::

::: fragment
→ We will periodically refer to specific guidelines throughout this class.
:::

::: fragment
> "Above all, professionalism in statistical practice presumes the goal of advancing knowledge while avoiding harm; using statistics in pursuit of unethical ends is inherently unethical."
:::

------------------------------------------------------------------------

## Responsibilities to Research Subjects

> "The ethical statistician protects and respects the rights and interests of human and animal subjects at all stages of their involvement in a project. This includes respondents to the census or to surveys, those whose data are contained in administrative records, and subjects of physically or psychologically invasive research."

------------------------------------------------------------------------

### Responsibilities to Research Subjects

Why do you think the `Age` variable maxes out at 80?

```{r, echo = FALSE, fig.asp = 0.35}
library(tidyverse)
library(NHANES)


ggplot(data = NHANES, mapping = aes(x = Age, y = Height)) +
  geom_point(alpha = 0.1) +
  geom_smooth(color = "skyblue") +
  labs(title = "NHANES: Age versus Height")
```

::: fragment
> "Protects the privacy and confidentiality of research subjects and data concerning them, whether obtained from the subjects directly, other persons, or existing records."
:::

## Next time: 

-   More sampling
-   Sampling bias
