---
pagetitle: "Logistic Regression"
editor: source
format: 
  revealjs:
    html-math-method: mathjax
    chalkboard: true
    incremental: true
    theme: [default, custom.scss]
    height: 900
    width: 1600
    slide-number: c
    auto-stretch: false
    callout-appearance: simple
    pdf-max-pages-per-slide: 2
    menu: 
      side: right
      numbers: true
execute:
  echo: true
  warning: false
  message: false
---

```{r}
#| include: false
#| warning: false
#| message: false
library(knitr)
library(tidyverse)
library(ggthemes)
library(moderndive)
library(gapminder)
library(infer)
library(gridExtra)
library(kableExtra)
```

::::: columns
::: {.column .center width="60%"}
![](img/DAW.jpeg){width="90%"}
:::

::: {.column .center width="40%"}
<br>

[Logistic Regression]{.custom-title}

<br> <br> <br> <br> <br>

[Grayson White]{.custom-subtitle}

[Math 141 <br> Week 14 \| Fall 2025]{.custom-subtitle}
:::
:::::

------------------------------------------------------------------------

### Goals for Today

-   Discuss summer opportunity
-   Introduce logistic regression


# Summer Opportunity: Undergraduate Forestry Data Science (UFDS)!

------------------------------------------------------------------------

### Undergraduate Forestry Data Science Summer Research

This summer, I'll be hiring Reed students in my undergraduate forestry data science (UFDS) program!

:::: {.columns}

::: {.column width=50%}

-   UFDS is a long-running collaboration with the **US Forest Service** where we answer statistical and data science research questions for the US Forest Service.

-   Students will work on problems generated by the Forest Service and will collaborate directly with Research Statisticians and Foresters at the Forest Service.

-   Co-directed by myself and Kelly McConville (Bucknell University), this summer's research will occur on Reed's campus and will include students from both colleges!


:::

::: {.column width=5%}

:::

::: {.column width=45%}

![](img/ufds.png)

:::

::::


------------------------------------------------------------------------


### Undergraduate Forestry Data Science Summer Research

This summer, I'll be hiring Reed students in my undergraduate forestry data science (UFDS) program!

Students will work in small groups on multiple projects throughout the summer. **Some tentative projects for this summer:**

:::: {.columns}

::: {.column width=45% .nonincremental}

-   In recent years, FIA has experienced greater need for estimates of forest parameters over smaller geographic regions. For example, the Forest Service manages wild fires and tries to estimate the impact of these fires on important forest attributes. This area of research is called **small area estimation**. This project will explore the utility of several different estimators for estimating forest attributes over small areas.


:::

::: {.column width=5%}

:::

::: {.column width=50%}

![](img/figure4(1).png)

:::

::::

------------------------------------------------------------------------

### Undergraduate Forestry Data Science Summer Research

This summer, I'll be hiring Reed students in my undergraduate forestry data science (UFDS) program!

Students will work in small groups on multiple projects throughout the summer. **Some tentative projects for this summer:**

:::: {.columns}

::: {.column width=50% .nonincremental}


-   **Bayesian statistics** is a field of statistics we have discussed but not engaged in this semester. The Forest Service is interested in using Bayesian statistics and models to operationalize **small area estimation**, but they need guidance on the mechanics of fitting these models. This project will first learn about, and then write a tutorial on, operationalizing Bayesian small area estimation for the forest service and in forest inventory settings more generally. 


:::

::: {.column width=5%}

:::

::: {.column width=45%}

![](img/pgm.png)

:::

::::

------------------------------------------------------------------------

### Undergraduate Forestry Data Science Summer Research

This summer, I'll be hiring Reed students in my undergraduate forestry data science (UFDS) program!

Students will work in small groups on multiple projects throughout the summer. **Some tentative projects for this summer:**

:::: {.columns}

::: {.column width=50% .nonincremental}


-   **Simulation studies** are crucial for understanding the properties of model-based estimators. And recently, the Forest Service has been interested in **assessing estimators that account for change** in the forest (from, e.g., a forest fire or clearcut). In this project, students will adapt the [KBAABB methodology](https://academic.oup.com/forestry/advance-article/doi/10.1093/forestry/cpaf071/8341163) to help assess estimators that estimate change.

:::

::: {.column width=5%}

:::

::: {.column width=45%}

![](img/kbaabb.png){width=60%}

:::

::::

------------------------------------------------------------------------


### Undergraduate Forestry Data Science Summer Research

This summer, I'll be hiring Reed students in my undergraduate forestry data science (UFDS) program!

**Some tentative details (subject to change):**

:::: {.columns}

::: {.column width=50%}

-   10 week program, starting June 1, 2026. 

-   Stipend included (approx: $6000)! (Actual amount and housing details TBD)

-   Ice cream excursions and lots of fresh fruit included! 

-   We are planning to **open applications over the break or in the first week of Spring semester**. So be on the lookout! (I will send an email to you all)






:::

::: {.column width=5%}

:::

::: {.column width=45%}

![](img/ufds.png)

:::

::::


# FAQs

------------------------------------------------------------------------

### Why should I do summer research?

- **Learning by doing data science**: Practicing data science can really help you develop as a data scientist.

- **Communication skills**: You will have multiple opportunities to share your work (both in writing and orally) to your peers, your mentor (me!), the stakeholders, and novices. I will give you feedback to help you hone your communication skills.

- **Professional identity and belonging**: Research can help strengthen your connection to the discipline of statistics.

- **Graduate school and career preparation/clarity**: The experience will demystify what research is, helping you decide if you want to pursue an advanced degree. And, grad school or not, the tools and skills learned will help prepare you for your professional life after undergrad.

- **And, it is fun**: The data are messy! The questions are vague! The answers are unknown! What more could you want?

------------------------------------------------------------------------

### Will I get to co-author a publication out of this? 

-   Maybe!

-   At the start of a project, it is very difficult to predict whether or not it will result in a publication. And, for some projects, a journal article may not be the most useful final product. So, I canâ€™t say with any certainty whether or not your work will be published but I can say that we will find ways for you to share the work. For example, the group will present their findings to Forest Service researchers and will be expected to participate in any relevant campus research presentation events.

------------------------------------------------------------------------

### What should I expect from a day of research?

-   The work will be highly collaborative. Most days we will have a team meeting in the morning where everyone presents their progress, discusses issues, and talks through their next steps. For the rest of the day, your time will likely be split between your projects and will be a mix of coding, writing, problem-solving, and dealing with merge conflicts in GitHub.

::: {.fragment}

![](img/research-timeline.png){width=62% fig-align='center'}

:::


------------------------------------------------------------------------


### Do I need to be a certain major to apply?

-   No way! UFDS fellows have been majors ranging from Mathematics to English to Statistics to Economics and beyond!

-   Diverse perspectives are always encouraged here. Coming from a different field often brings a very valuable and unique perspective!

<br>

::: {.fragment}


### What courses are required?

-   I hope that everyone in the program has taken Math 141 (good job, you have already done that)! Other experience in data science (such as Math 241) is very helpful! A computer science course can be helpful as well. 

-   Regardless of the courses taken, I expect prior experience coding in R and building statistical models (which you have done in Math 141).


:::


------------------------------------------------------------------------

### How do I apply? 

::: {.incremental}

Wait for the Summer 2026 application to be posted this winter break (or in the first week of Spring semester). I'll email you all once I have posted it!

![](img/Jing's tree art.png){width=80% fig-align='center'}

:::


# Logistic Regression

## Logistic Regression

Logistic regression can be used when:

-   Response variable: binary, categorical variable
-   Explanatory variables: Can be a mix of categorical and quantitative variables

------------------------------------------------------------------------

### Logistic Regression

**Response variable**: A **categorical** variable with **two** categories

```{=tex}
\begin{align*}
Y =   \left\{
\begin{array}{ll}
      1 & \mbox{success} \\
      0 & \mbox{failure} \\
\end{array} 
\right.  
\end{align*}
```
::: fragment
$Y \sim$ Bernoulli $(p)$ where $p = P(Y = 1) = P(\mbox{success})$.
:::

::: fragment
**Explanatory variables**: Can be a mix of categorical and quantitative
:::

::: fragment
**Goal**: Build a model for $P(Y = 1)$.
:::

------------------------------------------------------------------------

### Why can't we use linear regression?

::: columns
::: column
-   Regression line = estimated **probability** of success

-   For valid values of $x$, we are predicting the probability is less than 0 or greater than 1.

-   The estimated probabilities based on the logistic regression model are bounded between 0 and 1.
:::

::: column
```{r, echo=FALSE}
set.seed(40)
x <- c(runif(20, 0, .6), runif(20, 0.4, 1))
y <- c(rep(0, 20), rep(1, 20))
dat <- data.frame(x, y)
ggplot(dat, aes(x, y)) +
  geom_point(alpha = 0.5, size = 3) +
  geom_smooth(method = lm, se = FALSE) + 
  labs(y = "P(Y = 1)") +
  geom_smooth(method = 'glm', method.args = list(family = "binomial"), se = FALSE, color = "tomato")
```
:::
:::

::: fragment
What does the **logistic regression model** look like?
:::

------------------------------------------------------------------------

### Logistic Regression Model

```{=tex}
\begin{align*}
\log\left(\frac{P(Y = 1)}{1  - P(Y = 1)}  \right) &= \beta_o + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p 
\end{align*}
```
::: fragment
Left hand side has many interpretations:

```{=tex}
\begin{align*}
\mbox{LHS} &= \log\left(\frac{P(Y = 1)}{1  - P(Y = 1)}  \right)\\ 
&= \log \left( \mbox{odds (of success)}  \right)\\
&= \mbox{logit}(P(Y = 1))
\end{align*}
```
Note:

$$ 
\mbox{odds} = \frac{\mbox{prob of success}}{\mbox{prob of failure}}
$$
:::

------------------------------------------------------------------------

### Example

Let's look at the `forested` R package that contains a dataset on whether a given location in Washington state is considered to be "forested" or not (by the US Forest Service's definition of "forested"). We'll ask the question: Can we build a model to predict whether or not a location is forested given some useful predictors derived from satellite imagery and other remote sensing products? 

:::: {.columns}

::: {.column}

```{r}
library(forested)
data(forested)
```

:::

::: {.column}

![](img/forested.png){width=50% fig-align="center"}

:::

::::

------------------------------------------------------------------------

### Example


```{r}
forested <- forested %>%
  mutate(forested = case_when(forested == "Yes" ~ 1,
                              forested == "No" ~ 0)) 
str(forested)
```

-   Each row represents a plot collected by the US Forest Service
-   Response variable?
-   Potential good predictors?


------------------------------------------------------------------------


### Example

```{r}
#| output-location: column
forested %>%
  ggplot(mapping = aes(x = canopy_cover,
                     y = forested)) +
  geom_jitter(size = 3, alpha = 0.1,
              width = 0, height = 0.05) + 
  labs(y = "P(Y = 1)") +
  geom_smooth(method = 'glm',
              method.args = 
                list(family = "binomial"))
```

------------------------------------------------------------------------

### Example

::: columns
::: column
This is what an helpful explanatory variable looks like!

```{r, echo=FALSE}
forested %>%
  ggplot(mapping = aes(x = canopy_cover,
                     y = forested)) +
  geom_jitter(size = 3, alpha = 0.1,
              width = 0, height = 0.05) + 
  labs(y = "P(Y = 1)") +
  geom_smooth(method = 'glm',
              method.args = 
                list(family = "binomial"))
```
:::

::: column
This is what an unhelpful explanatory variable looks like!

```{r, echo = FALSE}
forested %>%
  ggplot(mapping = aes(x = northness,
                     y = forested)) +
  geom_jitter(size = 3, alpha = 0.1,
              width = 0, height = 0.05) + 
  labs(y = "P(Y = 1)") +
  geom_smooth(method = 'glm',
              method.args = 
                list(family = "binomial"))
```
:::
:::

# **Question**: How do we fit the model (the blue curve) in R?

------------------------------------------------------------------------

### Logistic Regression Table

```{r}
mod <- glm(forested ~ canopy_cover, data = forested, family = "binomial")
library(broom)
tidy(mod)
```



-   But what do the coefficient estimates $\hat{\beta}_0 = -2.230$ and $\hat{\beta}_1 = 0.087$ represent?

------------------------------------------------------------------------

### Interpretation of Coefficients

#### Recall the (2) following definitions:

**(1) Odds:**

$$\text{odds} = \frac{\text{prob of success}}{\text{prob of failure}} = \frac{P(Y = 1)}{1 - P(Y = 1)}$$

and **(2) the logistic regression model**:

$$\log\left(\frac{P(Y = 1)}{1 - P(Y = 1)}\right) = \beta_0 + \beta_1 x_1$$

::: {.fragment}

So then

$$\text{odds} = \exp\left(\beta_0 + \beta_1 x_1\right)$$

:::

------------------------------------------------------------------------

### Interpretation of Coefficients

#### New concept:

**Odds ratio**: Comparison of odds between two groups

$$\text{odds ratio} = \frac{\text{odds of group 1}}{\text{odds of group 2}}$$

**Interpretation of odds ratio:** The odds of success in group 1 are *insert #* times the odds of success in group 2.

<br>

::: {.fragment}

**Note:** Also useful property:

$$\exp(a + b) = \exp(a) \exp(b)$$

:::

------------------------------------------------------------------------

### Interpretation of Coefficients

(estimated) odds for $x_1 = t$\% covered canopy:

$$\exp\left(\hat{\beta}_0 + \hat{\beta}_1 t\right)$$

::: {.fragment}

(estimated) odds for $x_1 = (t + 1)$\% canopy cover:

$$\exp\left(\hat{\beta}_0 + \hat{\beta}_1 (t + 1)\right)$$

:::

::: {.fragment}

odds ratio:

$$\frac{\exp\left(\hat{\beta}_0 + \hat{\beta}_1 (t + 1)\right)}{\exp\left(\hat{\beta}_0 + \hat{\beta}_1 t\right)} = \frac{\exp(\hat{\beta}_0)\exp(\hat{\beta}_1 (t + 1))}{\exp(\hat{\beta}_0)\exp(\hat{\beta}_1 t)} = \exp(\hat{\beta}_1)$$

:::

------------------------------------------------------------------------

### Interpretation of Coefficients

How do we interpret $\hat{\beta}_1 = 0.087$?

$$\exp(\hat{\beta}_1) = \frac{\text{odds of being forested for canopy cover } (t + 1) \text{\%}}{\text{odds of being forested for canopy cover } t \text{\%}}$$

<br>

::: {.fragment}

```{r}
exp(0.087)
```


For every 1% increase in canopy cover, the odds of a location being forested are multiplied by 1.09.

:::

------------------------------------------------------------------------

### Prediction

How can I use this model to predict, for a given canopy cover, whether a plot is forested or not?

We can use the **predicted probability** at a plot to help us predict the **binary outcome**.

::: {.fragment}

$$\widehat{P(Y = 1)} \geq 0.5 \rightarrow \hat{y} = 1$$
$$\widehat{P(Y = 1)} < 0.5 \rightarrow \hat{y} = 0$$

:::

------------------------------------------------------------------------

### Prediction Accuracy

```{r}
preds <- predict(mod, newdata = forested, type = "response")
head(preds)
```

------------------------------------------------------------------------

### Prediction Accuracy

```{r}
forested2 <- forested %>%
  bind_cols(preds = preds) %>% # quickly add as a column
  mutate(pred_forested = case_when(
    preds >= 0.5 ~ 1,
    preds < 0.5 ~ 0
  ))

forested2 %>%
  count(forested, pred_forested)
```

-   Pretty good!
-   Still problems with over-fitting!
    -   Need to learn about splitting your data into testing and training sets (Math 243).

------------------------------------------------------------------------

### Next time: Wrap-Up!

-   Remember: we meet for lab **tomorrow** at our regular time and location.

-   Lot's of practice problems to work through!

-   (Logistic regression won't be on the final exam.)

